### 1.1 스파크

#### 1.1.2 빅데이터의 정의

"다앙햔 형태를 지닌 대량의 데이터가 빠른 속도로 쌓이고 있다면 이를 빅데이터라고 부를 수 있다"

빅데이터의 중요한 특성 세 가지는 크기, 속도, 댜양성입니다.

- 크기 : 대량의 데이터를 처리
- 속도 : 데이터의 증가가 지속적이고 빠르기 때문에 이에 부합하는 빠른 데이터 처리 기술이 필요
- 다양성 : 빅데이터의 다양성

#### 1.1.3 빅데이터 솔루션

먼저 빅데이터를 처리하는 플랫폼이니만큼 데이터를 가져오는 데이터 수집 모듈이 필요합니다. 다음으로는, 이렇게 수집된 데이터를 저장하고 조회하는 저장 및 조회 모듈이 필요합니다. 다음으로, 데이터를 분석하고 그 결과를 가공할 수 있는 모듈이 필요합니다. 그리고, 이제 이 모든 과정을 제어할 수 있는 워크플로우 엔진이 필요할 수도 있습니다. 

- 데이터 수집 : 플럼 / 카프카 / 스쿱
- 데이터 저장 및 처리 : 하둡 / HBase / 카산드라 / 레디스 / 피그 / 하이브 / 스파크
- 데이터 분석 및 기타 소프트웨어 : R / 클라우데라 / 엘라스틱서치

#### 1.1.4 스파크

##### 하둡이란

빅데이터라는 용어가 이렇게 대중적으로 알려지게 된 데는 하둡의 탄생과 성공이 크게 기여했습니다. 하둡은 구글이 대용량 처리와 관련해서 공개한 두 개의 논문을 Doug Cutting 이 실제 제품으로 구현하면서 시작된 아파치 프로젝트를 가리키는 이름입니다. 

하둡은 여러 대의 서버를 이용해서 하나의 클러스터를 구성하며, 이렇게 클러스터로 묶인 서버의 자원을 하나의 서버처럼 사용할 수 있는 클러스터 컴퓨팅 환경을 제공합니다. 기본 동작 방법은 **분석할 데이터를 하둡 파일 시스템인 HDFS 에 저장해 두고, HDFS 상에서 Map Reduce 프로그램을 이용해 데이터 처리를 수행하는 방식**입니다.

데이터를 저장할 때는 전체 데이터를 '블록' 이라고 하는 일정한 크기로 나눠서 여러 데이터 노드에 분산해서 저장합니다. 이 때, 각 블록들이 어느 데이터 노드에 저장돼 있는지에 대한 메타정보를 네임 노드에 기록합니다. 그리고 맵 리듀스 작업을 실행할때는 네임노드로부터 메타정보를 읽어서 처리할 데이터의 위치를 확인하고 분산 처리를 수행합니다.

##### 맵리듀스란

맵리듀스 프레임워크는 하둡의 대표적인 데이터 처리 프레임워크입니다. 데이터를 여러 개 의 맵 프로세스와 리듀서 프로세스로 나눠서 처리하는 방식입니다. **맵 프로세스는 여러 데이터 노드에서 분산 저장된 데이터를 각 서버에서 병렬로 나누어서 처리하며, 리듀서는 그러한 맵 프로세스들의 결과를 조합해 최종 결과를 만들어냅니다**.

맵리듀스 잡의 제어는 네임노드에서 구동되는 잡 스케쥴러와 태스크 스케쥴러라는 프로세스가 처리했습니다. 하지만, 기본적으로 하나의 클러스터에서 한개의 맵리듀서 잡만 구동할 수 있었기 때문에 CPU와 메모리를 효율적으로 사용하지 못했습니다. 그래서, 하둡 2.0 부터 데이터 처리 작업에 대한 스케쥴링과 서버 자원 관리를 YARN 이라는 자원 관리 시스템에서 전담하면서 이러한 문제점이 개선됐습니다. 

하둡만으로는 모든 데이터 처리를 수행하기에는 부족한 부분이 있었습니다.

- 하둡의 맵리듀스 잡은 대부분의 연산 작업을 파일 시스템 기반으로 처리해서, 스파크 같은 메모리 기반 데이터 처리 방식에 비해 상대적으로 높은 성능을 기대하기 어려웠습니다.
- 맵리듀스 잡을 이용해서 데이터를 처리하려면 대부분 자바 언어를 사용해서 맵리듀스 프로그램을 작성해야했습니다.
- 외부 라이브러리의 도움 없이 단위 테스트를 작성하거나 실제 데이터를 대상으로 간단한 시뮬레이션을 하기 어려웠습니다.
- SQL on Hadoop 인 하이브의 경우, 개발자들에게 친숙한 SQL 을 사용해서 맵리듀스 잡을 생성할 수 있지만, 이를 위해서는 미리 사용할 테이블과 데이터를 설계해야합니다.

스파크는 하둡과 달리 **메모리를 이용한 데이터 저장 방식을 제공**함으로써 머신러닝 등 반복적인 데이터 처리가 필요한 분야에서 높은 성능을 보여줬습니다. 또한, **작업을 실행하기 전에 최적의 처리 흐름을 찾는 과정**으로 성능 향과 더불어 여러 개의 맵리듀스 잡을 직접 순차적으로 실행해야하는 수고를 덜 수 있게 됐습니다. 특히, 맵리듀스에 비해 훨씬 자연스럽고 강력한 다수의 데이터 처리 함수를 제공함으로써 프로그램의 복잡도를 낮춰줍니다. 또한, 스파크 2.0 부터 자바, 스칼라, 파이썬 뿐만 아니라 R 스크립트를 이용해서도 스파크 어플리케이션을 작성할수 있게 됐습니다.

#### 1.1.5 RDD, Dataset, DataFrame 소개와 연산

스파크 프로그램 내에서 데이터를 표현하고 처리하기 위한 프로그래밍 모델을 제공하는에 용도에 따라, RDD / Dataset / DataFrame 이라는 세가지 모델을 제공합니다.

RDD 는 스파크에서 정의한 분산 데이터 모델로서 병렬 처리가 가능한 요소로 구성되며 데이터를 처리하는 과정에서 프로그램 오류가 아닌 메모리 공간 부족 등의 이유로 일시적인 문제가 발생하더라도 **스스로 에러를 복구 할 수 있는 능력을 가진 데이터 모델**입니다.

스파크는 RDD 가 생성되어 변경되는 모든 광정을 일일이 기억 (Lineage) 하는 대신에 RDD 를 한번 생성되면 변경되지 않는 읽기 전용 모델로 만든 후 RDD 생성과 관련된 내용만 기억하고 있다가 장애가 발생하면 이전에 RDD 를 만들 때 수행했던 작업을 똑같이 실행해 (똑같은 데이터를 가진 새로운 RDD를 만들어) 데이터를 복구하는 방식을 사용하는 것입니다.

RDD 는 크게 세가지 방법으로 생성할 수 있습니다.

- List 나 Set 같은 기존 프로그램의 메모리에 생성된 데이터를 이용하는 것입니다.
- 로컬 파일시스템이나 하둡의 HDFS 같은 외부 저장소에 저장된 데이터를 읽어서 생성합니다.
- 기존에 생성되어 있는 RDD 로부터 또 다른 RDD 를 생성하는 방법입니다.

RDD 를 생성하고 나면, RDD 가 제공하는 다양한 연산을 이용해 데이터를 처리하면 되는데, RDD 에서 제공하는 연산은 크게 Transformation 과 Action 이라는 두 종류로 나눌 수 있습니다.

- Transformation
  - 어떤 RDD 에 변형을 가해 새로운 RDD 를 생성하는 연산입니다. 변환 연산은 연산이 호출되는 시점에 바로 실행되는 것이 아니라, 변환을 어떻게 수행할 것인지에 대한 정보만 누적해서 가지고 있다가 Action 에 해당하는 연산이 호출될 때 한꺼번에 실행됩니다. 따라서 최종 실행이 필요한 시점에 누적된 변환 연산을 분석하고 그 중에서 최적의 방법을 찾아 변환 연산을 실행할 수 있습니다.
- Action
  - 연산의 결과로 RDD 가 아닌 다른 값을 반환하거나 아예 반환하지 않는 연산입니다.

#### 1.1.6 DAG

여러개의 꼭지점 또는 노드와 그 사이를 이어주는 방향성을 지닌 선으로 구성되고, 그래프를 구성하는 어느 꼭지점이나 노드에서 출발하더라도 다시 원래의 꼭지점으로 돌아오지 않도록 구성된 그래프 모델입니다.

스파크는 트렌스포메이션과 액션의 조합으로 데이터 흐름을 손쉽게 표현할 수 있습니다. 스파크에서 DAG 처리를 담당하는 부분을 DAG 스케쥴러라고합니다. 스케쥴러의 동작방식을 이해하기 위해서는 스파크의 작업 실행이 어떻게 수행되는지 이해해야합니다.

##### 스파크 작업 실행 순서 : Driver -> DAG Scheduler -> Cluster Manager

스파크는 전체 작업을 Stage 라는 단위로 나누고, 각 스테이지를 다시 여러 개의 테스크로 나누어 실행합니다. 이 때, 최초의 메인함수를 실행해 RDD 등을 생성하고 각종 연산을 호출하는 프로그램을 Driver 프로그램이라고 합니다. Driver 프로그램은 메인 함수를 가진 일발적인 프로그램으로 작성하면 됩니다.

드라이버의 메인 함수에서는 스파크 애플리케이션과 스파크 클러스터의 연동을 담당하는 SparkContext 또는 SparkSession 이라는 객체를 만들고 이를 이용해 잡을 실행하고 종료하는 역할을 수행합니다. 드라이버가 스파크컨텍스트를 통해 RDD 의 연산정보를 DAG 스케쥴러에게 전달하면 스케쥴러는 이 정보를 가지고 실행 계획을 수립한 후에 이를 클러스터 메니저에게 전달합니다. 이 때, 스케쥴러가 생성하는 정보는 주로 데이터에 대한 지역성을 높이는 전략과 관련된것입니다. 전체 데이터 처리 흐름을 분석해서 네트워크를 통한 데이터 이동이 최소화 되도록 스테이지를 구성하는 것을 주로 수행합니다.

#### 1.1.7 람다 아키텍쳐

빅데이터 처리를 위한 시스템을 구성하는 방법 중 하나입니다. 데이터를 처리하는 시스템을 일괄 처리를 담당하는 영역 (일괄 처리 계층) 과, 실시간 처리를 담당하는 영역 (속도 계층) 으로 나눈후 다음과 같이 운영합니다.

1. 새로운 데이터는 일관 처리 계층과 속도 계층 모두에 전달
2. 일괄 처리 계층은 원본 데이터를 저장하고 일정 주기마다 한번씩 일괄적으로 가공해서 Batch View (결과 데이터) 를 생성
3. 속도 계층은 들어오는 데이터를 즉시 또는 매우 짧은 주기로 처리해서 실시간 뷰를 생성
4. 서빙 계층은 실시간 뷰와 배치 뷰의 결과를 적절히 조합해서 사용자에게 데이터를 전달

정리하면, **일괄 처리 작업을 통해 데이터를 처리하되 아직 배치 처리가 수행되지 않은 부분은 실시간 처리를 통해 보완**한다는 개념입니다.

### 1.2 스파크 설치

#### 1.2.1 스파크 실행 모드의 이해

대부분의 빅데이터 소프트웨어들이 클러스터 환경에서 동작합니다. 클러스터란 **여러대의 컴퓨터가 하나의 그룹을 형성해서 마치하나의 컴퓨터인 것처럼 동작하는 것**을 의미합니다. 이처럼 여러 대의 서버가 마치 한 대의 서버처럼 동작해야하기 때문에 CPU 나 메모리, 디스크 등의 자원관리가 쉽지 않습니다. 

스파크나 하둡과 같이 클러스터 환경에서 동작하는 대부분의 프레임워크는 실행 모드라는 개념을 가지고 있습니다. 즉, 개발 및 테스트를 위해서는 1대의 단독 서버 혹은 개인 PC 에서 애플리케이션을 실행하고, 실 서비스에서는 여러 서버로 구성된 클러스터 환경에서 동일한 어플리케이션을 실행할 수 있는 것입니다.

#### 1.2.5 스파크 쉘

스파크 어플리케이션을 실행하기 위해서는 **메인 함수를 가진 어플리케이션을 작성하고, 스파크에서 제공하는 spark-submit 스크립트를 이용해서 실행**합니다. 

스파크는 프로그램을 작성해서 실행하는 방법 외에도, 인터렉티브 방식으로 프로그램을 작성할 수 있는 스파크 쉘도 제공합니다. 스파크 쉘은 사용하는 언어에 따라 스칼라, 파이썬, R 버젼으로 나눌 수 있습니다. 

#### 1.2.6 실행 옵션

스파크 쉘은 실행과 관련된 다양한 옵션을 제공합니다. "--help" 옵션으로 확인할 수 있습니다.

"--master" 옵션은 스파크가 사용할 **클러스터의 마스터 정보를 지정하는 옵션**입니다. 사용하는 클러스터 마스터 ( 혹은 메니저) 정보를 지정하는 옵션입니다.

만약 클러스터가 아닌 단일서버에서 동작시킬 경우에 "local" 이라고 입력합니다. 이 경우, 스파크 잡은 하나의 서버에서 하나의 스레드만 이용해서 동작합니다. 따라사 여러개의 스레들르 이용하려면 "local[2]" 처럼 지정합니다. 스레드 두 개를 사용한다는 의미입니다. "local[*]" 는 사용 가능한 모든 스레드를 사용합니다.

### 1.4 예제 프로젝트 설정

#### 1.4.1 WordCount 예제 실행

스파크 어플리케이션을 프로그래밍 하는 방법은, 

1. SparkContext 생성
2. 입력 소스로부터 RDD 생성
3. RDD 처리
4. 결과 파일 처리
5. SparkContext 종료