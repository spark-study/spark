# 1장 스파크 소개

## 1.1 스파크

### 빅데이터
* 크기(Volume)
* 다양성(Variety)
* 속도(Velocity)
* 가변성
* 정확성
* 복잡성
* 시인성


### 빅데이터 솔루션
* 데이터 수집 모듈 - 플럼, 카프카, 스쿱
* 데이터 저장 및 조회 모듈 - 하둡, HBase, 카산드라, 레디스, 하이브 ...
* 워크플로우 엔진 기능
* 등등...

### 스파크
* *하둡*은 HDFS + 맵리듀스
  * job의 제어는 네임노드에서 구동되는 **잡 스케줄러**와 **태스크 스케줄러**를 통해 이루어짐
  * 파일시스템 기반으로 처리
--- 
 * *SPARK*는 RDD라는 모델을 사용
  * 크게 RDD, DataFrame, Dataset이 존재
  * **RDD는 스파크 내부에 존재하는 "분산 데이터"에 대한 모델**
    * 장애가 발생할 경우 스스로 복구될 수 있는 내성(Tolerance)를 가지고 있다.
    * RDD는 파티션이라는 단위로 나누어질 수 있으며, 스파크에서는 파티션 단위로 병렬로 처리를 수행함
    * 파티션에 속한 데이터들이 다른 파티션으로 이동하는 경우가 있는데 이를 셔플링이라고 함
    * RDD는 읽기 전용으로 한번 생성이 되면 바뀌지 않음 *-COMMENT- immutable object 같은거라고 난 생각함*
  * linege는 RDD 생성 작업을 기록해 두는 것으로 장애발생시 이를 통해 장애가 발생하기 전 구간의 작업을 실행하여 복구 가능
  
 ---
  * *RDD 생성*
    * RDD는 3가지 방식으로 생성이 가능
      1. 메모리에서 생성된 데이터로 부터
      2. 로컬 파일이나 HDFS 같은 외부저장소에서
      3. RDD로부터 생성하는 방법
      
 ---
  * *RDD의 연산*
    * 트랜스포메이션
      * RDD에 변형을 가해 새로운 RDD를 만들어 내는 연산
      * Lazy Evaluation으로 실제 호출 시점에서는 바로 실행이 되지 않음  
        *-COMMENT- Python에 Generator, MAP등 Lazy 개념과 비슷해보이지만 차이가 있을 수 있으 듯*
    * 액션
      * Lazy로 미루어졌던 연산을 실제로 수행하는 연산
      * 트랜스포메이션은 리턴이 RDD 이지만 액션은 값
---
  * *DAG*
    * 빅데이터에서 DAG는 일련의 작업 흐름을 나타내는 용도로 많이 사용
    * 스파크에서는 DAG 스케줄러를 통하여 전체 작업에 대한 최적의 실행 경로를 판단하여 처리해줌
      1. 전체 작업을 스테이지라는 단위로 나눔
      2. 스테이지를 태스크로 나눔
      3. 이를 DAG 스케줄러에게 넘기면 실행 계획을 수립한 후 클러스터 매니저에게 전달하여 실행
      
---
  * 람다 아키텍처 [http://lambda-architecture.net/]
      ![](http://lambda-architecture.net/img/la-overview_small.png)
      
      * 일괄 처리를 담당하는 영역 + 실시간 처리를 담당하는 영역
      * 실시간 처리영역이 다소 정확하지 않을 수 있지만, 추후 일괄 처리를 통하여 보정
