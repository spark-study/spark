- 애플리캐이션 단위로 설정
  - Spark Properties 사용
- 각 서버 단위로 설정
  - 서버의 환경 변수를 이용해 등록

### 4.1 스파크 프로퍼티

스파크 프로퍼티는 개별 애플리캐이션 실행관 관련된 설정값을 정의하는 곳입니다. 스파크 컨텍스트를 생성할 때 사용했던 SparkConf 인스턴스나 자바 시스템 프로퍼티를 이용해 등록 가능합니다.

```scala
var sparkConf = new SparkCont().setAppName("myApp")
val sc = new SparkContext(sparkConf)
```

SparkConf 클래스는 스파크 애플리캐이션 실행관 관련된 다양한 설정 정보를 키와 값 형태로 등록할수 있는 함수(set / get) 을 제공합니다. 애플리캐이션 이름과 같이 반드시 지정해야 하는 주요 속성에 대해서는 setMaster, setAppName 과 같은 별도의 메서드를 제공합니다.

SparkConf 를 이용하는 것의 문제점은 애플리캐이션의 비즈니스 로직과는 직접 관련이 없는 익스큐터의 메모리 설정이나 코어 수 할당관 관련된 부분이 항상 프로그램 코드에 포함돼 있어야 한다는 것입니다. 그래서, 프로그램이 실행되는 시점에 동적으로 필요한 설정값을 설정할수 있는 두 가지 방법이 있습니다.

1. spark-shell / spar-submit

   스크립트 실행시 사전에 지정된 형식에 따라 명령행 옵션을 이용해 원하는 설정값을 지정합니다.

2. 설정 정보가 담긴 파일 사용

   스파크 홈의 conf 디렉터리 아래에 spark-defaults.conf 파일을 만들고 이 파일에 설정 정보를 등록해 두면 스파크 쉘이나 sprak-submit 스크립트가 해당 파일의 내용을 읽습니다. 

### 4.2 환경변수

각 서버 단위로 적용돼야 하는 환경 정보는 각 서버의 환경 변수를 이용해 등록할 수 있습니다. 예를 들어, 자바의 설치 경로와 같은 정보가 서버별로 다르게 설정돼 있다면 환경변수를 이용해 해당 서버의정보를 변경할 수 있습니다. 환경 변수 ex )

- JAVA_HOME : 자바 설치 경로
- SPARK_LOCAL_IP : 사용할 IP
- SPARK_PUBLIC_DNS : 애플리케이션 호스트명
- SPARK_CONF_DIR : spar-defaults.conf / spark-env.sh / log4j.properties 파일 등 설정 파일이 놓인 디렉토리 위치

일부 환경 변수는 사용하는 클러스터 매니저의 종류에 따라 설정 방법이 다릅니다.

### 4.3 로깅 설정

스파크는 로깅 프레임워크로 log4j 를 사용합니다. 로깅 레벨을 변경하고 싶으면 스파크 홈의 conf 디렉토리 아래에 log4j.properties 파일을 생성하고 원하는 레벨로 설정하면 됩니다.

### 4.4 스케쥴링

하나의 애플리캐이션에 무조건 많은 CPU 와 대량의 메모리를 할당한다고 해서 원하는 속도가 나온다는 보장이 없습니다. 오히려, GC 발생과 과도한 IO, 네트워크, 프로세스 경항 등으로 인해 처리 속도가 더 나빠질 수 있습니다.

이번 절에서는 스파크 애플리캐이션을 수행할 때 클러스터 자원을 각 자원에 적절히 분배해서 사용하는 방법을 정리합니다.

하나의 클러스터에서 여러 작업이 실행되는 경우는 두 가지 입니다.

1. 서로 다른 애플리캐이션이 동일한 클러스터에서 동시에 실행
2. 하나의 애플리캐이션에서 여러 스레드를 이용해 다수의 잡을 동시에 실행

#### 4.4.1 애플리캐이션 간의 자원 스케쥴링

1. 애플리캐이션 단위로 고정된 자원을 할당해주는 고정 자원 할당 방식

   각 애플리케이션별마다 할당된 자원을 미리 결정한뒤 애플리케이션이 실행되는 시점부터 종료되는 시점까지 해당 자원을 계속 점유하는 사용방식입니다. 

   스파크셸 이나 spark-submit 을 이용해 애플리케이션을 실행할 때 사용할 자원 정보를 지정할 수 있습니다.

   만약, 실행되는 애플리케이션이 짧은 시간에 집중적으로 처리를 수행하는 애플리케이션이 아닌, 스파크 셸이나 웹 기반의 애플리케이션 처럼 장시간 동작하면서 사람 혹은 외부 프로스세가 제공하는 이벤트가 있을 때만 작업을 처리하는 형태로 동작하는 애플리케이션이라면 외부로부터의 명령을 대기하는 시간 동안 자원의 낭비가 발생합니다.

   따라서, 작업을 수행하지 않고 외부의 작업 요청을 대기하는 동안에는 해당 자원을 회수해서 자원이 부족한 다른 애플리케이션에 추가로 할당하는 것이 합리적입니다.

2. 애플리캐이션의 실행 상황에 따라 수시로 할당량을 조정해 주는 동적 자원 할당 방식

   스탠드얼론 모드를 제외하고는 모두 별도의 셔플 서비스를 구동시킵니다. 왜냐하면, 동적 자원 할당 모드에서는 애플리케이션이 실행되고 있는 도중에 익스큐터가 스케쥴러에 의해 삭제될 수 있기 떄문입니다.

   아직 리듀서가 읽어가지 않은 데이터를 갖고 있던 익스큐터가 스케쥴러에 의해 삭제되면 셔플 데이터가 유실되기 때문에 익스큐터가 삭제되더라도 해당 데이터를 유지하고 처리될 수 있게 별도의 셔플 프로세스를 설정하는 것입니다.

#### 4.4.2 단일 애플리캐이션 내부에서의 자원 스케쥴링

스파크컨텍스트는 기본적으로 멀티스레드 방식을 지원합니다. 하나의 스파크컨텍스트에서 다수의 액션 연산을 동시에 실행하더라도 문제가 없습니다. 하지만, 별도의 설정이 없다면 잡의 실행은 기본적으로 FIFO 방식입니다. 문제점은 먼저 시작되는 작업이 우선권을 얻어 자원을 모두 점유한 채 실핼됭 경우, 후속 작업은 이전 작업이 모두 완료되지 전까지 대기하고 있어야한다는 점입니다.

스파크는 그래서 FIFO 스케쥴러와 fail-scheduler 를 선택할 수 있는 옵션을 제공합니다. 

```scala
conf.set("spark.scheduler.mode", "FAIR")
```

페어 스케쥴링 방식을 사용하면, 모듭 잡은 동일한 자원을 번갈아가며 할당받습니다. 크기가 작은 잡과 수행 시간이 오래 걸리는 잡이 섞여 있을 때 크기가 작은 잡이 크기가 큰 잡을 기다리지 않고 빠른 처리가 가능합니다. 하지만 경우에 따라서는 중요한 작업과 덜 중요한 적업을 구분해서 자원 할당의 우선순위를 조정해야 하는 경우도 있습니다.

그래서, Pool 이라는 개념을 도입해 풀마다 스케쥴링 방식과 우선순위, 사용 가능한 자원 할당 수준을 다르게 설정한 뒤 각 잡을 특정 풀에 할당해 풀 단위로 작업을 관리할 수 있습니다.