# 4장 스파크 설정

#### 4.1 스파크 프로퍼티

- 스파크 프로퍼티 : 개별 애플리케이션 실행과 관련된 설정값들을 정의하는 곳

  ```scala
  val sparkConf = new SparkCont().setAppName("myApp")
  val sc = new SparkContext(sparkConf)
  ```

  - SparkConf를 이용해 속성값을 지정할 때, 애플리케이션의 비즈니스 로직과는 관련 없는 설정관련 코드가 코드에 포함되어 있어야 함 → 별로 좋지 못함

  - 동적으로 설정값을 넣어주는 방법이 2가지 존재

    1. 스파크셸이나 spark-summit스크립트를 이용하는 방법

       ```shell
       spark-shell --master yarn --num-executors 8 ...
       ```

    2. 설정 정보가 담긴 파일을 사용하는 방법 

       ```
       spark-defaults.conf에 설정값을 지정
       ```

       

#### 4.2 환경변수

- 스파크 애플리케이션과 관련된 설정 정보는 스파크 프로퍼티를 이용해서 설정

- 각 서버 단위로 적용되어야 하는 환경 정보는 각 서버의 환경변수를 이용해서 등록



#### 4.3 로깅 설정

- 스파크에서는 log4j를 이용해서 로깅함
- 로그 레벨 설정시 conf 디렉토리 내에서 log4j.properties 파일을 이용하여 설정



#### 4.4 스케줄링

- 애플리케이션의 수행속도를 높이기 위해서 CPU와 메모리를 많이 할당한다고 해서 무조건 빨라지지는 않음
  - 오히려 GC발생과 과도한 IO 등으로 느려질 수 있음
- 여러 작업이 실행되는 경우 크게 2가지방법으로 자원을 분배하여 실행
  1. 서버로 다른 어플리케이션이 동일한 클러스터에서 동시에 실행
  2. 하나의 어플리케이션에서 여러개 스레드를 이용해 다수의 잡을 동시에 실행하는 경우



##### 4.4.1 애플리케이션 간의 자원 스케줄링

- 여러 애플리케이션이 하나의 클러스터를 공유하는 경우 자원 스케줄링 방법

1. **고정 자원 할당 방식**
   - 각 어플리케이션마다 할당할 장뤈을 미리 결정한 뒤 애플리케이션이 해당 자원을 점유하고 사용하는 방식
   - 스탠드얼론모드, 메소스의 파인-그레인 모드일 때 적용
2. **동적 자원 할당 방식**
   - 작업을 수행하는 경우에만 자원을 할당하는 것
   - 작업 대기 등 상태 일 때 해당 자원을 반납해서 다른 어플리케이션에서 할당



##### 4.4.2 단일 애플리케이션 내부에서의 자원 스케줄링

- 하나의 어플리케이션 내부에서 여러 잡이 수행되는 경우 스케줄러를 2개 지원
  1. FIFO 스케줄러 : 이전 잡이 끝나야 진행, 후속 작업은 대기
  2. 페어 스케줄러 : 라운드로빈 방식, 일정 타임 만큼 각 잡들이 진행
