# 스파크 2 프로그래밍 정리

- ## 4장 스파크 설정
    1. 스파크 프로퍼티
        - 스파크 프로퍼티란? = 어플리케이션 실행과 관련된 설정값들을 정의하는 곳.
        - SparkConf 인스턴스나(get, set 메소드 존재)자바 시스템 프로퍼티를 이용하여 설정 가능.
        - SparkConf 이용시 비즈니스 로직에 연관이 없는 설정값이 코드에 항상 포함해야하는 단점이 있다. 
            1. 스파크 쉘 혹은 spark-submit을 이용하면 위 단점 해결
            2. 스파크 홈에 spark-defaults.conf 파일에 정의를 하여 단점 해결
        
        - 어플리케이션 관련 설정
            
            
            property 명 | 의미 | default
            -- | -- | --
            spark.app.name | 어플리케이션 이름 | X(필수로 세팅 필요)
            spark.driver.cores | 드라이버가 사용할 코어 수 | 1
            spark.driver.maxResultSize | 액션연산으로 생성된 값의 최대 크기 | 1G
            spark.driver.memory | 드라이버가 사용할 메모리 크기(클라이언트 모드 시 SparkConf가 아닌 --driver-memory로 지정해야함) | 1G
            spark.executor.memory | 익스큐터 하나의 메모리 크기 | 1G
            spark.local.dir | RDD 데이터 저장 혹은 셔플 시 매퍼의 데이터 저장을 하는 경로 | /tmp
            spark.master | 클러스터 매니저 정보 | -
            spark.submit.deployMode | 디플로이 모드 지정(client 혹은 cluster) | -

            ---
            
        - 실행환경 관련 설정

            property 명 | 의미 | default
            -- | -- | --
            spark.driver.extraClassPath | 드라이버 클래스패스에 추가할 항목 지정(SparkConf가 아닌 --driver-class-path로 지정해야함.) | -
             spark.executor.extraClassPath | 익스큐터의 클래스패스에 추가할 항목 지정 | -
             spark.files, spark.jars | 각 익스큐터의 실행 dir에 위치한 파일, jars 지정(, 를 사용하여 여러개 지정 가능) | -
             spark.submit.pyFiles | PYTHON_PATH에 추가될 .zip, .egg, .py 파일 지정(, 를 사용하여 여러개 지정 가능) | -
             spark.jars.pachages | 익스큐터와 드라이버의 클래스패스에 추가될 의존성 jar 정보 지정 | -

             ---
        
        - 셔플 관련 설정

            property 명 | 의미 | default
            -- | -- | --
            spark.reducer.maxSizeFlight | 셔플시 각 리듀서가 읽어갈 때 사용할 버퍼 사이즈 | 48m
            spark.reducer.maxReqslnFlight | 리듀서에서 매퍼 결과를 가져갈때 동시에 수행가능항 최대 요청 수 | int.MaxValue(2147483647)
            spark.shuffle.compress | 매퍼의 결과를 압축 유무(true시 spark.io.compress.codec 지정) | false
            spark.shuffle.service.enabled | 외부 셔플 서비스 사용 유무 | false
            ---
        
        - 스파크 UI 관련 설정
            
            property 명 | 의미 | default
            -- | -- | --
            spark.eventLog.enabled | 스파크 이벤트 로그 수행 유무(true시 spark.eventLog.dir에 로깅 경로 지정해야함, 스파크 UI에서 확인 가능) | false
            spark.ui.port | 스파크 UI 포트 | 4040
            spark.ui.killEnabled | 스파크 UI를 통해 job kill 가능 여부 | true
            spark.ui.retainedJobs | 종료된 잡 정보 유지 갯수 | -
            ---

        - 압축 및 직렬화 관련 설정

            property 명 | 의미 | default
            -- | -- | --
            spark.broadcast.compress | 브로드 캐스트 변수값을 압축할지 유무 | true
            spark.io.compression.codec | 스파크 내부에서 사용할 압축 방법 | lz4
            spark.kyro.classesToRegister | Kyro 직렬화에 사용할 클래스 지정 | -
            spark.serializer | 스파크에서 사용할 객체 직렬화 방식(스파크에서는 JavaSerializer, KyroSerializer 클래스 제공)  | -
            ---

        - 메모리 관련 설정
            
            property 명 | 의미 | default
            -- | -- | --
            spark.memory.fraction | 스파크 여유/가용 메모리 비율 설정 | 0.6
            spark.memory.storageFraction | 스파크 가용공간에서 저장에 사용할 메모리 비용 | 0.5
            spark.memory.offHeap.enabled | off 힙 메모리 사용 유무 | false
            ---

        - 익스큐터 관련 설정
            
            property 명 | 의미 | default
            -- | -- | --
            spark.executor.cores | 익스큐터에 할당할 코어 수(얀 경우 1, 나머지는 사용가능한 코어 수) | -
            spark.default.parallelism | 스파크에서 사용할 파티션 수 | -
            spark.files.fetchTimeout | sparkContext.addFile() 메소드 사용 시 파일 받아오는 limit 시간 | 60s
            ---
        
        - 네트워크 관련 설정

            property 명 | 의미 | default
            -- | -- | --
            spark.driver.host, spark.driver.port | 드라이버 프로세스의 호스트와 포트 | -
            spark.network.timeout | 스파크의 default 네트워크 타임아웃 값 | -
            ---

        - 보안 관련 설정
            
            property 명 | 의미 | default
            -- | -- | --
            spark.acls.enable | 스파크 acl 활성화 여부 | false
            spark.admin.acls | 스파크 잡에 접근가능 user, admin 설정( , 를 사용하여 다수 등록 가능 / group으로 설정할 시 spark.admin.acls.group 속성 사용) | -
            spark.authenticate | 스파크에서 사용자 인증 여부 확인 유무 | false
            spark.authenticate.secret | 잡 실행 시 시크릿 키 정보 설정 | -
            spark.ui.view.acls, spark.ui.view.acls.groups | 스파크 UI에서 잡 조회 acl 정보 | -
            spark.ui.filters | 스파크 UI에 적용할 서블릿 필터 지정( , 를 사용하여 다수 등록 가능) | -
            ---
        
        - 프로펄티 우선 순위
            1. 코드 상 SparkConf
            2. spark-shell, spark-submit
            3. spark-defaults.conf 파일
            
    2. 환경변수
        
        - 스파크 애플리케이션이 아닌 서버 단위로 적용해야하는 정보는 각 서버의 환경변수 이용
        
        - 환경변수로 설정 가능한 항목
            1. JAVA_HOME : 자바 설치 경로
            2. PYSPARK_PYTHON : 파이썬 경로
            3. PYSPARK_DRIVER_PYTHON : 파이썬 경로(드라이버에만 적용)
            4. SPARK_DRIVER_R : R경로
            5. SPARK_LOCAL_IP : 사용할 ip 경로
            6. SPARK_PUBLIC_DNS : 애플리케이션 호스트명
            7. SPARK_CONF_DIR : spark-defaults.conf, spark-env.sh, log4j.properties 등 설정 파일이 놓인 디렉터리 위치

        - 클러스터 매니저에 따라 설정 방법 상이

        - ```얀으로 클러스터 모드 사용 시 환경변수는 spark-defaults.conf 파일의 spark.yarn.appMasterEnv.[환경변수명] 이용해야함.```

    3. 로깅설정
        - 로깅 관련 설정을 log4j.properties에 기입(log4j.properties.template 파일을 복사하여 사용)
        - 로깅파일이 저장되는 경로는 각 클러스터 매니저마다 다름

        클러스터 매니저 | 로깅 저장 경로
        -- | --
        스탠드 얼론 | 각 슬레이브 노드의 spark 홈 아래 work 디렉토리
        메소스 | /var/log/mesos
        얀 | 기본 각 노드의 로컬 파일 시스템(yarn.log-aggregation-enable이 true의 경우 yarn.nodemanager/remote-app-log-dir에 설정된 경로)

    4. 스케줄링

        - 클러스터에서 수행되는 작업은 해당 작업에 적당한 cpu, memory를 주는 것이 성능을 최대화 시킨다(과도하게 주는 경우 GC, IO, 네트워크 등의 경합이 더 비효율적일 수 있음)
        - 하나의 클러스터에서 다수의 잡이 실행되는 경우 스케쥴링을 적절히 선택 및 이용하여 최적의 성능을 맞추어야함.
        
        - 2개 이상의 애플리케이션이 하나의 클러스터에서 동작할 시 2개의 스케쥴링 방법 사용 가능
            1. 고정 자원 할당 방식( = 각 애플리케이션마다 할당할 자원을 미리 결정)
                - 사용 방법은 위에서 설명한 spark-shell, spark-submit 사용.
                - 단기간이 아닌 웹같은 장기간 동작하며 이벤트 발생이 있을때, 수행되는 경우에는 비효율적!! 이때는 동적 자원할당 방식을 이용
            2. 동적 자원 할당 방식( = 상황에 따라 자원을 할당 및 회수하는 방식)
                - 클러스터 마다 동적 자원 할당 방식이 상이
                - 공통 설정 = spark.dynamicAllocation.enabled 속성 true 사용

                클러스터 모드 | 동적자원 할당 방식
                -- | --
                스탠드얼론 | spark.shuffle.service.enabled 속성 true 사용
                메소스 | 1. spark.mesos.coarse, spark.shuffle.service.enabled 속성을 true로 설정<br> 2. 각 워커노드마다 start-mesos-shuffle-service.sh 수행
                얀 | 1. spark-<version>-yarn-shuffle.jar를 모든 노드매니저 클래스패스에 등록<br> 2. 각 노드 매니저의 yarn-site.xml 파일에 아래와 같이 속성 설정<br> 2-1.spark_shuffle=yarn.nodemanager.aux-services <br> 2-2.yarn.nodemanager.aux-services.spark_shuffle.class=org.apache.spark.network.yarn.YarnShuffleService<br> 2-3/park.shuffle.service.enabled=true

        - 1개 애플리케이션에서 여러 잡이 수행되는 경우 스케쥴링 방법
            1. FIFO = 기본 설정값이며, 수행요청대로 잡이 리소스를 점유하게된다
                - 단시간에 끝나는 잡이 오래 걸리는 잡 뒤에 있을때 단점
            2. FAIR = 
                - sparkConf에 spark.scheduler.mode=FAIR 로 사용 가능.
                - FAIR에서도 우선순위를 조절하고 싶은 경우 pool을 사용.
                - pool 설정은 conf 디렉토리에 fairscheduler.xml 파일에 기재, 예제는 아래와 같다

                ```xml
                <?xml version="1.0"?>
                <allocations>
                    <pool name="pool1">
                        <schedulingMode>FAIR</schedulingMode>
                        <weight>1</weight>
                        <minShare>FAIR</minShare>
                    </pool>
                    <pool name="pool2">
                        <schedulingMode>FIFO</schedulingMode>
                        <weight>2</weight>
                        <minShare>3</minShare>
                    </pool>
                </allocations>
                ```
                - pool 지정 시 사용하는 속성

                    속성 | 의미
                    -- | --
                    schedulingMode | 스케쥴링 방법
                    weight | pool간의 우선순위(크기가 큰값이 높음)
                    minShare | pool이 가져야 하는 CPU 코어 수

                - 사용 방법
                    1. conf.set("spark.scheduler.allocation.file", "pool 설정 파일 경로")
                    2. sc.setLocalProperty("spark.scheduler.pool","pool1") -> pool 사용하지 않는 경우 null 값 세팅!!