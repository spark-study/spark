---
layout: post
title:  "[스파크2 프로그래밍] 2장_RDD"
date:   2019-07-16
categories: Spark
---

### 2.1 RDD

이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해

#### 2.1.1 들어가기에 앞서

RDD 다루기 전에 알아야 할 것

1. 스파크 클러스터

   클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.

2. 분산데이터로서의 RDD

   RDD 는 회복력을 가진 분산 데이터 집합입니다.

3. 불변성

   한번 만들어진 RDD 는 어떤 경우에도 변경되지 않습니다.

4. 파티션

   RDD 데이터는 클러스터를 구성하는 여러 서버에 나누어서 저장됩니다. 스파크는 분할된 데이터를 파티션이라는 단위로 관리합니다.

5. HDFS

6. Job 과 Executor

   스파크 프로그램을 실행하는 것을 스파크 잡을 실행한다고 합니다. 하나의 잡은 클러스터에서 병렬로 처리되고, 각 서버마다 익스큐터라는 프로세스가 생성됩니다. 각자 할당된 파티션을 처리합니다.

7. 드라이버 프로그램

   드라이버란, 스파크 컨텍스트를 생성하고 그 인스턴스를 포함하는 있는 프로그램입니다.

8. 트랜스포메이션과 액선

   트랜스포메이션은 RDD 의 형태를 변형하는 연산입니다. 액선은 어떤 동작을 수행해 그 결과로서 RDD 가 아닌 다른 타입의 결과를 변환하는 연산입니다.

9. 지연 동작과 최적화

   트랜스포메이션 연산은 RDD 를 사용하는 다른 액션 연산이 호출될때까지는 실제 트랜스포메이션을 수행하지 않습니다. 따라서, 실행 계획의 최적화가 가능합니다. **사용자가 입력한 변환 연산들을 즉시 수행하지 않고 모아뒀다가 한 번에 실행함으로써 불필요한 네티워크 통신 비용을 줄일 수 있습니다.**

10. 함수의 전달

#### 2.1.2 스파크 컨텍스트 생성

스파크컨텍스트는 **스파크 애플리케이션과 클러스터의 연결을 관리하는 객체**로서 스파크 애플리케이션은 반드시 스파크 컨텍스트를 생성해야합니다. 클러스터 마스터 정보와 애플리케이션 이름은 반드시 지정해야하는 필수정보입니다.

```java
SparkConf conf = new SparkConf().setMaster("local[*]").setAppName("RDDCreateSample");
JavaSparkContext sc = new JavaSparkContext(conf);
```

#### 2.1.3 RDD 생성

RDD 생성 방법 두가지가 있습니다.

1. 드라이버 프로그램의 컬렉션 객체 이용

   컬렉션 객체는 자바나 파이썬의 경우에는 리스트 타입을 사용합니다.

   ```java
   JavaRDD<String> rdd = sc.parallelize(Arrays.asList("a","b","c","d","e"));
   ```

2. 파일과 같은 외부 데이터 이용

   스파크는 내부적으로 하둡의 입력 및 출력 기능을 사용하므로 하둡이 다룰 수 있는 모든 입출력 유형을 다룰 수 있습니다.

   파일의 각 줄은 한 개의 RDD 구성요소가 됩니다. 파일을 읽어들이는 과정은 하둡의 TextInputFormat 을 이용합니다. 

   ```java
   JavaRDD<String> rdd = sc.textFile("<spark_home_dir>/README.md");
   ```

#### 2.1.4 RDD 기본 액션

##### 2.1.4.1 collect

RDD 의 모든 원소를 모아서 배열로 돌려줍니다. 반환 타입이 RDD 가 아닌 배열이므로 이 연산은 액션에 속하는 연산입니다. RDD 에 있는 모든 요소들이 collect 연산을 호출한 서버의 메모리에 수집됩니다. 따라서 충분한 메모리 공간이 확보되어야합니다.

```java
JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10));
List<Integer> result = rdd.collect();
for (Integer i : result) System.out.println(i);
```

##### 2.1.4.2 count

RDD 구성하는 전체 요소 개수 반환합니다.

```java
JavaRDD<Integer> rdd = sc.parallelize(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10));
long result = rdd.count();
System.out.println(result);
```

#### 2.1.5 RDD 트랜스포메이션

**기존 RDD 를 이용해 새로운 RDD 를 생성**하는 연산입니다.

- Map 연산
  - 요소간의 mapping 을 정의한 함수를 RDD 에 속하는 모든 요소에 적용해 새로운 RDD 를 생성
- 그룹화 연산
  - 특정 조건에 따라 요소를 그룹화 하거나 특정 함수를 적용
- 집합 연산
  - RDD 에 포함된 요소를 하나의 집합으로 간주할 때 서로 다른 RDD 간에 합집합, 교집합 등을 계산
- 파티션 연산
  - RDD 의 파티션 개수를 조정
- 필터, 정렬 연산
  - 특정 조건을 만족하는 요소만 선택하거나 각 요소를 정해진 기준에 따라 정렬

#### 2.1.6 RDD 액션

RDD 메서드 중에서 **결과값이 정수나 리스트, 맵 등 RDD가 아닌 다른 타입**인 것들입니다. 

트렌스포메이션에 속하는 메서드는 느긋한 평가 방식을 사용합니다. 즉, 호출한다고 즉시 실행되는 것이 아니라 액션으로 분류되는 메서드가 호출되어야하만 비로소 실행됩니다. 액션 메서드를 호출하는 시점이 돼서야 비로소 그동안 쌓여있던 ~개의 트렌스포메이션 연산이 순차적으로 시작됩니다.

**주의할점은, 액션 메서드를 여러번 호출하면 트렌스포메이션 메서드도 여러번 실행됩니다.** 예를 들어, rdd1 이라는 RDD 에 map() 연산을 적용해 rdd2 라는 RDD 를 만들었다고 할때, rdd2 의 액션 메서드를 두번 호출하면 map() 연산도 두번 실행됩니다. 따라서, 반복 수행 성능을 개선하기 위해 캐쉬를 적절히 사용하고, 코드 작성시 반복 수행 가능성을 염두해야합니다.

#### 2.1.7 RDD 데이터 불러오기와 저장하기

스파크는 하둡 API 를 기반으로 다양한 데이터 포맷과 파일 시스템을 지원합니다.

- 파일 포맷
  - 텍스트 파일 / JSON / 하둡의 시퀀스 파일 / csv ...
- 파일 시스템
  - 로컬 파일 시스템 / HDFS / AWS 의 S3 / 오픈스택의 Swift ...

##### 2.1.7.1 텍스트 파일

스파크는 다양한종류의 파일 시스템을 다룰수 있기 때문에 파일의 경로를 지정하는 방법도 파일 시스템의 종류에 따라 다릅니다.

- 로컬파일 시스템
  - file:///path
- HDFS
  - hdfs://master:prot/path/..
- S3
  - S3n://bucket/path

**주의할점은, 스파크가 클러스터를 이루는 다수의 서버 상에서 동작하기 때문에,  위에서 지정한 경로는 클러스터를 구성하는모든 서버에서 동일하게 접근 가능해야합니다.** 따라서, 로컬 파일 시스템의경로를 데이터 위치로 지정하면 클러스터를 구성하는 모든 서버에서 "file:///data/sample.txt" 라는 경로를 통해 지정한 파일로 접근할 수 있어야합니다.

```java
JavaRdd<Integer> rdd = sc.parallelize(fillToN(1000),  3); // 0~1000 까지의 숫자로 구성, 3개 파티션
Class codec =. org.apache.hadoop.io.compress.GzipCodec.class;

// save
rdd.saveAsTextFile("<path_to_save>/sub1");
rdd.saveAsTextFile("<path_to_save>/sub2",  codec);

// load
JavaRDD<String> rdd2 = sc.textFile("<path_to_save>/sub1");
```

##### 2.1.7.2 Object File

텍스트 파일을 사용하는 것과. 크게 다르지 않습니다. 다만, RDD 에 포함된 데이터를 오프젝트 파일로 다루기 위해서는 각 요소(오브젝트) 가 자바의 Serializable 인터페이스를 구현하고 있어야합니다. 그리고, 저장된 RDD 의 타입이 RDD[Int]  였다면, 이 파일으 읽어서 생성한 RDD 도 동일한 RDD[Int] 타입입니다.

```java
JavaRdd<Integer> rdd = sc.parallelize(fillToN(1000),  3); // 0~1000 까지의 숫자로 구성, 3 개 파티션

// save
rdd.saveAsObjectFile("<path_to_save>/sub_path");

// load
JavaRDD<Integer> rdd2 = sc.objectFile("<path_to_save>/sub_path");
System.out.println(rdd2.take(10));
```

##### 2.1.7.3 시퀀스 파일

키와 값으로 구성된 데이터를 저장하는 이진 파일 포맷입니다. 하둡에서 자주 사용되는 대표적인 파일 포맷입니다. 시퀀스 파일로다루고자 하는 RDD의 데이터는 하둡의 Wriable 인터페이스를 구현하고 있어야합니다.

#### 2.1.8 클러스터 환경에서의 공유 변수

하둡이나 스파크와 같이 클러스터 환경에서 동작하는 애플리케이션은 하나의 잡을 수행하기 위해 클러스터에 속한 다수의 서버에서 여러 개의 프로세스를 실행하므로 모든 프로세스가 공유할 수 있는 자원을 관리하기 쉽지 않습니다. **이러한 프레임워크는 다수의 프로세스가 공유할 수 있는 읽기 자원과 쓰기 자원을 설정할 수 있도록 지원합니다.**

- 하둡
  - 분산캐시 / 카운터
- 스파크
  - 브로드캐스트 변수 / 어큐뮬레이텨

1. 브로드캐스트 변수

   스파크 잡이 실행되는 동안 클러스터 내의 모든 서버에서 공유할 수 있는 읽기 전용 자원을 설정할 수 있는 변수입니다.

   - 먼저 공유하고자 하는 데이터를 포함하는 오브젝트를 생성
- 이 오브젝트를 스파크컨텍스트의 broadcast() 메서드의 인자로 지정해 해당 메서드를 실행
   - 이렇게 생성된 브로드캐스트 변수를 사용할때는 생성한 브로드캐스트 변수의 value() 메서드를 통해 접근

   클러스터 간에 공유할 변수가 있다고 해서 무조건 브로드캐스트 변수를 사용해야하는 것은 아닙니다. **액션 연산을 수행할때 동일한 스테이지 내에서 실행되는 태스크 간에는 필요한 변수를 자동으로 브로드캐스트 변수를 이용해서 전달**하기 때문에 명시적으로 브로드 캐스트 변수를 지정하지않아도 됩니다. 

2. 어큐뮬레이터

   쓰기 동작을 위한것입니다. 클러스터 내의 모든 서버가 공유하는 쓰기 공간을 제공함으로써 **각 서버에서 발생하는 특정 이벤트의 수를 세거나 관찰하고 싶은 정보를 모아두는 용도로 활용할 수 있습니다.** 

   어큐뮬레이터를 생성하려면 org.apache.spark.util.AccumulatorV2 클래스를 상속받은 클래스를 정의하고, 이 클래스의 인스턴스를 생성합니다. 그리고 생성한 어큐뮬레이터 인스턴스를 스파크컨텍스트가 제공하는 register() method 를 이용해 등록합니다. 

   어큐뮬레이터를 사용할 때는 두 가지를 기억해야합니다.

   첫 째, 어큐뮬레이터를 증가시키는 동작은 클러스터의 모든 데이터 처리 프로세스에서 가능하지만 데이터를 읽는 동작은 드라이버 프로그램 내에서만 가능합니다. 즉, RDD 의 트랜스포메이션이나 액션 연산 내부에는 어큐뮬레이터의 값을 증가시킬뿐 그 값을 참조해서 사용하는 것은 불가능합니다. 

   둘 째, 일부러 의도한 특별한 목적이없는 한 어큐뮬레이터는 액션 연산을 수행하는 메서드에서만 사용해야합니다. 왜냐하면 트렌스포매이션 연산은 액션 연산과 달리 하나의 잡 내에서 필요에 따라 수차례 반복 실행될 수 있기 때문입니다. 따라서 map(), flatmap() 과 같은 트랜스포메이션 연산 내용에 어큐뮬레이터의 값을 증가시키는 코드가 포함될 경우 정확하지 않은 데이터가 집계 될 수 있습니다.
