### 3.1 클러스터 환경

이번 장의 목표 : 분산 처리를 위한 시스템 아키텍처와, 그와 관련된 다양한 설정 및 매개변수를 이해하는 것.

스파크에서는 클러스터 자원을 관리해주는 역할을 하는 컴포넌트 클래스를 클러스터 매니저라고 합니다. 2.3.0 버젼에서는 네 종류의 클러스터 매니저가 사용되고 있습니다.

#### 3.1.1 클러스터 모드와 컴포넌트

스파크 클러스터는 **드라이버 / 클러스터 매니저 / 익스큐터 / 워커 노드**의 조합.

클러스터란, 여러 대의 서버가 네트워크를 통해 연결되어 마치 하나의 서버인 것처럼 동작하는 방식을 의미합니다. 전체 서버의 자원과 동작을 세밀하고 효율적으로 제어할 수 있는 별도 모듈을 클러스터 매니저라고 부릅니다.

스파크에서는  추상화된 클러스터 모델을 제공함으로써 사용하는 클러스터의 종류에 상관없이 일관된 방법으로 프로그램을 작성하고 클러스터를 관리할 수 있게 지원하고 있습니다.

"스파크 애플리케이션을 실행했다" 라고 하는 말은, 드라이버 프로그램에 있는 메인 함수를 실행해 스파크컨텍스트를 생성하고, 이를 이용해 각 워커 노드에 익스큐터 프로세스를 구동시켜 작업을 수행했다라는 뜻입니다. 즉, 익스큐터 하나가 사용할 자원(CPU 나 메모리) 을 정한뒤, 작업 실행 요청이 발생할 때마다 필요한 수만큼의 익스큐터를 할당하는 방식으로 자원을 할당합니다.

사용가능한 스파크컨텍스트가 준비돼 있다는 것은 클러스터 메니저와의 연동을 포함해서, 스파크 애플리케이션이 동작하는 데 필요한 다수의 서비스가 준비돼 있다는 의미이며, 이렇게 생성된 스파크컨텍스트를 이용해 RDD 나 브로드캐스트 또는 어큐뮬레이터 변수를 생성하고 사용할수 있음을 의미하는 것입니다.

쇼핑몰 방문자의 방문 로그를 분석하는 작업을 한다고 가정하고 작업을 수행하는 절차를 보겠습니다.

1. 드라이버 프로그램이 포함된 애플리케이션 코드를 작성
2. 코드를 빌드하고 jar 나 zip 파일 등으로 패키징
3. 생선한 패키지 파일을 스파크에서 제공하는 spark-submit 셸을 이용해 클러스터에 배포하고 실행
4. 스파크 애플리케이션의 드라이버 프로그램이 실행되면 스파크컨텍스트가 생성되면서 클러스터 매니저와 연동되어 각 클러스터 서버에 작업을 처리하기 위한 프로세스를 생성. 이때 작업에 필요한 서버를 워커노드라고 하며, 각 워커노드에 생성된 프로세스를 익스큐터.
5. 익스큐터가 생성되면 드라이버 프로그램은 작성된 프로그램에 의해 트렌스포메이션과 액션을 수행. 트렌스포메이션 연산이 호출할 때는 실제 작업을 수행하지 않고 액션 여산이 호출될 때만 실제 작업을 수행하느데, 이 작업 단위를 Job. 즉, 잡은 액션 연산의 수만큼 생성.
6. 생성된 잡은 실제로 수행될 때 스테이지라는 단계로 나누어 실행. 스테이지를 나누는 기준이 되는 것은 데이터 셔플 필요 여부. 즉, 각 서버에 있는 데이터를 네트워크를 통해 다른 서버로 재배치해야 하는지 여부. 셔플이 발생하면 네트워크를 통해 대량의 데이터를 정렬하고 전송하는 등의 부하가 발생해 전체 작업 성능에 좋지 않은 영향을 끼치기 때문. 따라서, 데이터를 이동하지 않는 상태에서 처리할 수 있는 연산을 최대한 같은 스테이지로 묶어 처리하면 셔플 발생을 최소화.
7. 각 스테이지는 여러 개의 태스크로 나눠진 후 분산처리를 위해 여러 익스큐터에 할당되며, 이 태스크가 실제 익스큐터에 전달되는 작업의 단위. 이 때, 익스큐터는 두 가지 역할 수행. 하나는 할당받은 테스크를 처리. 다른 하나는 이미 처리된 데이터를 나중에 빠르게 재사용할 수 있게 메모리에 저장.

#### 3.1.2 클러스터 모드를 위한 시스템 구성

일반적으로, 별도의 서버에 애플리케이션을 배포한 뒤 해당 서버에서 드라이버 프로그램을 구동하고 실제 데이터 처리는 스파크 클러스터에서 수행되게 하는 방법을 사용합니다. 이렇게, **클러스터에 작업을 요청하는 서버를 배치 서버 또는 클라이언트 서버라고 부릅니다.** 

다음은 클러스터 구성에 필요한 서버의 종류입니다.

1. 로컬 개발 서버

2. 애플리케이션 실행 서버

   spark-submit, spark-shell 등의 스크립트를 이용해 스파크 어플리케이션을 맨 처음 실행하는 서버.

3. 클러스터 서버

   클러스터 구성에 참여하는 서버. 클러스터 운영을 위한 마스터 서버의 역할을 수행하거나, 실제 데이터를 처리하고 필요에 따라 저장하는 워커 노드의 역할을 수행하는 서버입니다. 

#### 3.1.3 드라이버 프로그램과 디플로이 모드

모든 스파크 어플리케이션에는 스파크컨텍스트를 생성하는 코드가 포함돼 있는데, 이 부분이 포함된 프로그램을 가리켜 드라이버 프로그램이라고 합니다. 클러스터에서 실행할 때는 클러스터 매니저에게 애플리케이션 실행을 요청합니다. ("제출한다" 라고 합니다.)

작업 요청을 받은 클러스터 매니저는 필요한 자원을 할당하고 작업을 수행하는데, 클러스터 매니저마다 다른 형태로 애플리케이션을 실행시킬 수 있습니다. 이처럼 서로 다른 실행 모드를 '디플로이 모드' 라고 합니다. '클라이언트 디플로이 모드' 와 '클러스터 디플로이 모드' 가 있습니다.

**클라이언트 디플로이 모드란, 애플리케이션을 실행한 프로세스 내부에서 드라이버 프로그램을 구동하는 것**으로, 드라이버 프로그램은 작업을 요청한 클라이언트 서버 프로세스에 포함되어 실행됩니다. 따라서 스파크 어플리케이션을 실행했던 콘솔을 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시키면 스파크컨텍스트도 함께 종료되면서 수행 중이던 모든 스파크 잡이 중지 됩니다.

**클러스터 디폴로이 모드란, 애플리케이션을 실행한 프로세스는 클러스터 매니저에게 작업 실행만 요청하고 즉시 종료되며, 실제 드라이버 프로그램의 실행은 클러스터 내부에서 실행되는 것**을 의미합니다. 클러스터 매니저에게 잡이 전달되고 최초 어플리케이션을 실행했던 콘솔들 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시켜도 전체 스파크 어플리케이션의 동작에는 영향을 끼치지 않습니다.

### 3.2 클러스터 매니저

스파크의 클러스터 모드를 구성하는 컴포넌트. 중 하나로 여러 대의 서버로 구성된 클러스터 환경에서 다수의 어플리케이션이 함께 구동될 수 있게 어플리케이션 간의 CPU 나 메모리, 디스크와 같은 컴퓨팅 자원을 관리해주는 역할을 합니다. 하둡의 Yarn 이나 아파치 Mesos 등이 있습니다.

#### 3.2.1 스탠드얼론 클러스터 매니저

스파크나 하둡과 같이 클러스터 환경에서 동작하는 대부분의 프레임워크는 실행 모드라는 개념을 가지고 있습니다. 즉, 개발 및 테스트를 위해서는 1대의 단독 서버 혹은 개인 PC 에서 애플리케이션을 실행하고, 실 서비스에서는 여러 서버로 구성된 클러스터 환경에서 동일한 어플리케이션을 실행할 수 있는 것입니다.

##### 3.2.1.1 개요

스탠드얼론 클러스터 매니저는 마스터/슬레이브 개념으 도입해 **하나의 마스터 인스턴스와 다수의 슬레이브 인스턴스로 클러스터를 구성**합니다. 이를 스파크의 클러스터 컴포넌트 모넬 관점에서 보면, 마스터 인스턴스가 클러스터 매니저 컴포넌트에 해당하고 슬레이브 인스턴스는 워커 노드에 해당합니다.

마스터는 클러스터 매니저의 역할을 담당해서 **클라이언트의 요청을 받아 필요한 서버 자원을 할당하고 슬레이브의 작업 실행을 관리하는 기능을 수행**합니다. 슬레이브는 Worker 의 역학을 담당하면서 **Executor 와 Task 를 실행해 데이터에 대한 실제 처리와 저장**을 수행합니다.

클러스터를 시작하는 방법은, 마스터 인스턴스를 구동한 뒤에. 마스터의 접속 주소를 슬레이브 인스턴스의 실행 인자로 전달하면서 슬레이브 프로세스를 구동시킵니다. 스파크 어플리케이션을 동작시키는 경우에는 마스터 서버의 주소를 maseter 속성 값으로 지정해서 실행합니다.

##### 3.2.1.2 설치

스탠드얼론 클러스터 매니저를 사용하려면 클러스터를 구성하는 모든 서버에 스파크가 설치되어 있어야합니다.

설치가 끝나면 먼저 마스터 인스턴스를 실행한 후 슬레이브 인스턴스를 실행합니다. 실행 스크립트를 이용하려면, 마스터와 슬레이브 프로세스가 실행된 서버 간에 패스워드 없이 SSH 접속이 가능하도록 설정해야합니다.

##### 3.2.1.3 클러스터 매니저 실행

마스터 서버에 접속한 뒤 스파크 홈 아래에 있는 sbin 디렉토리로 이동합니다. 이 디렉토리에는 스탠드얼론 클러스터 매니저의 실행과 종료를 위한 다수의 실행 스크립트가 있습니다.

- 마스터 인스턴스와 슬레이브 인스터스를 개별적으로 실행할 때 사용할 수 있는 스크립트
- 마스터 서버를 비롯한 다수의 슬레이브 인스턴스를 한번에 실행하거나 종료할 때 사용하는 스크립트

##### 3.2.1.4. 애플리케이션 실행 서버 준비

이제 클러스터 매니저를 이용해 원하는 작업을 실행해볼 차례입니다. 작업을 실행하는 방법은 세 가지가 있는데, 그 전에 애플리케이션을 배포해서 실행할 서버를 결정해야합니다. 클러스터를 구성하는 서버 중 하나를 사용할 수도 있고 별도의 서버를 사용할 수 있는데 일반적으로 별도의 서버를 사용합니다. 

##### 3.2.1.5 애플리케이션 실행

스파크 셸 / pyspark / spark-submit 세 가지 방법이 있습니다.

###### 3.2.1.5.1 스파크 셸

컴파일이나 배포 과정을 거치지 않고 셸에서 직접 코드를 입력하고 그 결과를 즉시 확인할 수 있는 인터랙티브한 개발환경을 제공함으로써 코드의 작성과 디버깅을 손쉽게 할 수 있습니다.

스파크 셸도 일종의 스파크 어플리케이션이기 때문에 마스터 정보를 전달해야합니다.  클러스터 마스터 URL 이 'spark://svr01:7077' 이면, 애플리케이션 실행 서버에서 아래와 같이 실행합니다.

```sh
$ ./bin/spark-shell --master spark://svr01:7077
```

###### 3.2.1.5.2 pyspark

스파크 셸과 같은 기능을 수행하며 파이썬 언어를 사용하는 경우에 사용할 수 있습니다.

###### 3.2.1.5.3 spark-submit

스파크 어플리케이션을 실행하는데 필요한 각종 설정 값을 명확하고 일관된 방식으로 정의할 수 있기 때문에, 자바 스칼라 파이썬 등의 언어로 작성된 어플리케이션을 동일한 방법으로 실행가능합니다.

##### 3.2.1.6 디플로이 모드

디플로이 모드를 지정하는 방법은 클러스터 매니저의 종류에 따라 다를수 있는데 스탠드얼론 매니저를 사용할 경우 --deploy-mode 옵션을 사용해 cluster 와 client 모드 중 하나를 지정할 수 있습니다.

##### 3.2.1.7 주요 설정

##### 3.2.1.8 HA

스탠드얼론 클러스터 모드는 하나의 마스터 + 다수의 워쿼 로 구성됩니다. 마스터는 각 워커에 작업을 지시하고, 작업 수행 상태를 모니터링하다가 워커 중 하나에 문제가 생기면, 그 워카가 수행하던 작업을 다른 워커에 전달해서 전체 작업이 문제 없이 처리되게 합니다. 하지만 워커가 아닌 마스터에 문제가 생기면 작업은 복구하지 못하고 실패합니다.

스탠드얼론 클러스터 모드는 주키퍼를 사용해 다수의 마스터 서버를 동일한 클러스터의 마스터로 지정하고, 문제가 발생할 경우 다른 마스터로 전환할 수 있게 함으로써 단일 마스터 서버 운영으로 인한 장애 발생 가능성을 낮출 수 있습니다.

#####3.2.1.9 단일 노드 복구

로컬 디렉토리의 특정 위치에 클러스터의 상태 정보를 저장해뒀다가 장애가 발생하면 저장된 정보를 이용해 다시 예전 상태를 복구하는 방식입니다. 

#### 3.2.2 아파치 매소스

#### 3.2.3 얀

하둡에서 제공하는 클러스터 자원 관리 서비스입니다. 얀의 등장 배경을 살펴봅시다.

하둡은 잡 트랙커와 테스크 트래커 프로세스를 이용해서 하둡의 대표적인 애플리케이션인 맵리듀스 어플리케이션을 실행하는 방법을 사용하고 있었습니다. 두 프로세스는 마스터와 슬레이브 관계로, 하나의 잡 트레커가 다수의 태스크 트레커를 관리하는 형태로 동작했습니다. 클러스터에서 수행되는 모든 잡은 잡 틀래커 프로세스를 통해 처리됐습니다.

하지만 잡 트래커는 전체 클러스터에서 하나만 실행됐기 때문에 **하나의 클러스터에서 여러 개의 에플리케이션이 실행될 경우 하나의 잡 트래커가 전체 어플리케이션의 자원 할당, 실행 제어, 모니터링, 히스토리 관리에 이르는 모든 처리를 수행해야하는 문제**가 있었습니다.

결국 이렇게 하나의 마스터 프로세스에 의존하는 배치 프로세싱 모델은 마스터 프로세스의 한계가 전체 클러스터의 한계로 이어지는 결과를 가져왓습니다.

얀은 이러한 기존 맵리듀스 프레임워크의 문제점을 개선하기 위해 제안된 것으로, **잡 트래러가 가지고 있던 자원 관리와 작업처리 모니터링 및 히스토리 관리 기능을 각각 별개의 서비스로 분리**한 것입니다. 

##### 3.2.3.1 개요

크게 봤을 때, 얀은 **클라이언트 프로그램 / 리소스 메니저 / 노드 매니저 / 애플리케이션 마스터 / 컨테이너** 등의 컴포넌트로 나눠볼 수 있습니다.

얀 어플리케이션 실행 과정은 다음과 같습니다.

1. 얀은 전체 크러스터의 자원을 관리하는 리소스 매니저와 각 노드의 자원을 관리하는 노드 매니저라는 두 종류의 데몬 프로세스로 구성돼있습니다. 노드 매니저는 클러스터를 구성하는각 노드에서 동작하는 데몬으로 해당 노드의 자원을 관리하고 노드가 보유하고 있는 자원 현황을 주기적으로 리소스 메니저에게 보고해서 리소트 메니저가 전체 클러스터의 자원현황을 알 수 있게 합니다. 리소스 매니저는 노드 매니저로부터 각 노드의 리소스 현황을 보고 받고 이를 관리하며 클러스터 내의 모든 어플리케이션의 실행에 필요한 자원을 할당하고 관리합니다.
2. 클라이언트 프로그램은 리소스 매니저에게 어플리케이션 (==어플리케이션 마스터) 를 실행해달라고 요청하는 프로그램입니다. 일반적으로 클라이언트 프로그램을 실행하는 서버는 클러스터에 속하지 않는 별도의 외부서버입니다.
3. 클라이언트 프로그램으로부터 어플리케이션 실행 요청을 받은 리소스 매니저는 노드 매니저 중에서 어플리케이션 마스터를 실행할 수 있는, 가용 자원이 있는 노드 매니저를 찾아서 어플리케이션 마스터의 실행을 요청합니다. 실행된 어플리케이션 마스터는 리소스 매니저에게 등록하는 절차를 거치며, 리소스 매니저는 이렇게 등록된 어플리케이션 마스터를 통해 전체 리소스를 관리합니다.
4. 리소스 매니저로부터 어플리케이션 마스터 실행 요청을 받은 노드 매니저는 어플리케이션 마스터 생성에 필요한 자원을 컨테이너라는 단위로 할당하고 컨테이너에 할당된 자원 (CPU 나 메모리) 를 이용해 어플리케이션 마스터를 실행한 뒤 자원 할당 결과를 리소스 메니저에게 보고합니다.
5. 어플리케이션 마스터가 실행되면 해당 어플이케이션에서 필요한 작업을 수행합니다. 

스파크의 클러스터 컴포넌트 모델과 얀의 컴포넌트 모델은 어떤 관계가 있을까?

1. 클라이언트 프로그램이 실행되면서 얀 리소스 매니저에게 애플리케이션을 실행해 줄것을 요청하면 리로스 매니저가 적절한 노드 매니저 하나를 선택해 애플리케이션 마스터를 실행. 이때 어플리케이션 마스터는 스파크 애플리케이션을 위해 작성된 것으로 클러스터 디플로이 방식이면 드라이버 프로그램이 같은 프로세스 내에서 수행.
2. 애플리케이션 마스터는 리소스 매니저에게 스파크 애플리케이션 실행에 필요한 자원을 요청해 이를 수행시킬 노드 목록을 전달받고, 해당 노드 매니저에게 필요한 자원 할당 및 프로세스 실행 요청.
3. 애플리케이션 마스터로부터 애플리케이션 프로세스 실행 요청을 받은 노드 매니저들은 필요한 자원은 담고 있는 컨테이너를 할당하고 요청받은 애플리케이션 프로세스 실행. 실행되는 애플리케이션 프로세스가 곧 스파크의 익스큐터.
4. 익스큐터가 실행되면 스파크 드라이버 프로그램이 생성된 익스큐터 프로세스를 이용해 스파크의 테스트 수행.

##### 3.2.3.2 설치

##### 3.2.3.3 스파크 잡 실행

다른 클러스터 매니저와 같습니다. 다만, 클러스터 마스터 URL 을 직접 지정하는 방법이 다릅니다.

###### 3.2.3.3.1 스파크 쉘

마스터에 대한 접속 정보를 하둡의 설정 파일을 통해 읽어드리므로, --master 매개변수에 그냥 'yarn' 이라고만 입력하고 대신 하둡의 설정파일 (core-site.xml, yarn-site.xml 등) 이 있는 디렉토리 경로를 'HADOOP_CONF_DIR' 또는 'YARN_CONF_DIR' 이라는 환경변수로 등록해야합니다.

##### 3.2.3.3.2 pyspark

##### 3.2.3.3.3 spark-submit

##### 3.2.3.4 디플로이 모드

다른 클러스터 매니저와 크게 다르지 않아서, --deploy-mode 매개변수의 값으로 client 나 cluster 를 지정합니다.

클라이언트 디플로이 모드이면, 얀 클라이언트 프로그램에서 실행되는 드라이버가 애플리케이션 동작을 제어하고 얀의 어플리케이션 마스터는 단순히 노드 매니저에게 필요한 자원을 요청하는 역할을 합니다.

##### 3.2.3.5 얀 컨테이너 로그 설정

스파크 어플리케이션이 실행되면 드라이버 프로그램이 제공하는 (드라이버 프로그램이 생성한 스파크 컨텍스트가 제공하는) 모니터링 페이지를 통해 해당 어플리케이션의 모니터링 및 디버깅에 필요한 각종 정보를 확인할 수 있습니다.

#### 3.2.4 히스토리 서버와 매트릭스

스파크컨텍스트가 제공하는 모니터링 페이지는 애플리케이션이 실행 중일 때만 접속가능합니다.

스파크에서는 이렇게 애플리케이션이 종료된 후에도 과거 이벤트 로그를 활용해 어플리케이션에 대한 정보를 볼 수 있게 하는 히스토리 서버를 제공합니다.

"--master" 옵션은 스파크가 사용할 **클러스터의 마스터 정보를 지정하는 옵션**입니다. 사용하는 클러스터 마스터 ( 혹은 메니저) 정보를 지정하는 옵션입니다.

만약 클러스터가 아닌 단일서버에서 동작시킬 경우에 "local" 이라고 입력합니다. 이 경우, 스파크 잡은 하나의 서버에서 하나의 스레드만 이용해서 동작합니다. 따라사 여러개의 스레들르 이용하려면 "local[2]" 처럼 지정합니다. 스레드 두 개를 사용한다는 의미입니다. "local[*]" 는 사용 가능한 모든 스레드를 사용합니다.
